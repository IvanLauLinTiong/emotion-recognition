{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eabf088",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a164957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15f8b7",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838bf727",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"angry\", \n",
    "    \"disgust\", \n",
    "    \"fear\", \n",
    "    \"happy\", \n",
    "    \"sad\", \n",
    "    \"surprise\", \n",
    "    \"neutral\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ac1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # dataset\n",
    "    TRAIN_DS_PATH = './dataset/train.csv'\n",
    "    VAL_DS_PATH = './dataset/val.csv'\n",
    "    TEST_DS_PATH = './dataset/test.csv'\n",
    "    \n",
    "    # images dir\n",
    "    TRAIN_IMG_DIR = './dataset/train/'\n",
    "    VAL_IMG_DIR  = './dataset/val/'\n",
    "    TEST_IMG_DIR  = './dataset/finaltest/'\n",
    "    \n",
    "    # training hyperparams\n",
    "    EPOCHS = 10\n",
    "    LR = 1e-4\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 0\n",
    "    SHUFFLE = True\n",
    "    \n",
    "    # saved model path\n",
    "    MODEL_DIR = './model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a43450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53622bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard writer\n",
    "writer = SummaryWriter(\"runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd927d2d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e5d1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/omarsayed7/Deep-Emotion/blob/master/data_loaders.py\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, datatype, transform):\n",
    "        '''\n",
    "        Pytorch Dataset class\n",
    "        params:-\n",
    "                 csv_file : the path of the csv file    (train, validation, test)\n",
    "                 img_dir  : the directory of the images (train, validation, test)\n",
    "                 datatype : data type for the dataset   (train, val, test)\n",
    "                 transform: pytorch transformation over the data\n",
    "        return :-\n",
    "                 image, labels\n",
    "        '''\n",
    "        self.csv_file = pd.read_csv(csv_file)\n",
    "        self.labels = self.csv_file['emotion']\n",
    "        self.img_dir = img_dir\n",
    "        self.datatype = datatype\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img = Image.open(self.img_dir + self.datatype + str(idx) + '.jpg').convert('RGB')\n",
    "        labels = np.array(self.labels[idx])\n",
    "        labels = torch.from_numpy(labels).long()\n",
    "\n",
    "        if self.transform :\n",
    "            img = self.transform(img)\n",
    "        return img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4cb1d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranformations\n",
    "transformation= transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,], std=[0.5,])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e89fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "train_dataset = EmotionDataset(\n",
    "    csv_file=cfg.TRAIN_DS_PATH, \n",
    "    img_dir=cfg.TRAIN_IMG_DIR,\n",
    "    datatype='train',\n",
    "    transform=transformation\n",
    ")\n",
    "\n",
    "validation_dataset = EmotionDataset(\n",
    "    csv_file=cfg.VAL_DS_PATH, \n",
    "    img_dir=cfg.VAL_IMG_DIR,\n",
    "    datatype='val',\n",
    "    transform = transformation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0348a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=cfg.BATCH_SIZE, \n",
    "    shuffle =cfg.SHUFFLE, \n",
    "    num_workers=cfg.NUM_WORKERS\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    validation_dataset, \n",
    "    batch_size=cfg.BATCH_SIZE, \n",
    "    shuffle =cfg.SHUFFLE, \n",
    "    num_workers=cfg.NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404ce34",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab87596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, steps_print_loss=0):\n",
    "    \"\"\"Train the model for 1 epoch\n",
    "    Args:\n",
    "        model: nn.Module\n",
    "        train_loader: train DataLoader\n",
    "        criterion: callable loss function\n",
    "        optimizer: pytorch optimizer\n",
    "        device: torch.device\n",
    "        steps_print_loss: loss will print out in every specified steps.\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Float, Float]\n",
    "        average train loss and average train accuracy for current epoch\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    train_corrects = []\n",
    "    model.train()\n",
    "\n",
    "    # Iterate over data.\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # prediction\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        train_losses.append(loss.item())\n",
    "        train_corrects.append(torch.sum(preds == labels.data).item())\n",
    "        \n",
    "        if steps_print_loss and (batch_idx % steps_print_loss == 0):\n",
    "            print(f\"loss: {loss.item():>7f}  [{batch_idx:>5d}/{len(train_loader):>5d}]\")\n",
    "        \n",
    "    train_loss = sum(train_losses)/len(train_losses)\n",
    "    train_accuracy = sum(train_corrects)/len(train_loader.dataset)      \n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model for 1 epoch\n",
    "    Args:\n",
    "        model: nn.Module\n",
    "        val_loader: val DataLoader\n",
    "        criterion: callable loss function\n",
    "        device: torch.device\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Float, Float]\n",
    "        average val loss and average val accuracy for current epoch\n",
    "    \"\"\"\n",
    "\n",
    "    val_losses = []\n",
    "    val_corrects = []\n",
    "    model.eval()\n",
    "\n",
    "    # Iterate over data\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # prediction\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # calculate loss\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # statistics\n",
    "            val_losses.append(loss.item())\n",
    "            val_corrects.append(torch.sum(preds == labels.data).item())\n",
    "            \n",
    "        val_loss = sum(val_losses)/len(val_losses)\n",
    "        val_accuracy = sum(val_corrects)/len(val_loader.dataset)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e735a5",
   "metadata": {},
   "source": [
    "# Training and Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b36628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = models.mobilenet.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "888b5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe3cfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:cuda for training\n"
     ]
    }
   ],
   "source": [
    "# transfer to cuda device if any\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Using device:{device} for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c76f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, optimizer and scheduler \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=cfg.LR)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a93309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.963119  [    0/ 3589]\n",
      "loss: 1.736238  [  500/ 3589]\n",
      "loss: 1.622846  [ 1000/ 3589]\n",
      "loss: 1.515492  [ 1500/ 3589]\n",
      "loss: 1.814029  [ 2000/ 3589]\n",
      "loss: 1.745634  [ 2500/ 3589]\n",
      "loss: 1.367832  [ 3000/ 3589]\n",
      "loss: 1.790536  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.7197 \tAverage TrainAcc: 0.3010\n",
      "Evaluation:\n",
      "Average ValLoss: 1.6131 \tAverage ValAcc: 0.3664\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.336309  [    0/ 3589]\n",
      "loss: 1.311972  [  500/ 3589]\n",
      "loss: 1.804169  [ 1000/ 3589]\n",
      "loss: 1.727910  [ 1500/ 3589]\n",
      "loss: 1.772702  [ 2000/ 3589]\n",
      "loss: 1.372732  [ 2500/ 3589]\n",
      "loss: 1.378198  [ 3000/ 3589]\n",
      "loss: 1.421382  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.6418 \tAverage TrainAcc: 0.3515\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5710 \tAverage ValAcc: 0.3915\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.612230  [    0/ 3589]\n",
      "loss: 1.671921  [  500/ 3589]\n",
      "loss: 1.232558  [ 1000/ 3589]\n",
      "loss: 1.323457  [ 1500/ 3589]\n",
      "loss: 1.360630  [ 2000/ 3589]\n",
      "loss: 1.248539  [ 2500/ 3589]\n",
      "loss: 1.675336  [ 3000/ 3589]\n",
      "loss: 1.643337  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.6171 \tAverage TrainAcc: 0.3594\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5562 \tAverage ValAcc: 0.3945\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.485185  [    0/ 3589]\n",
      "loss: 1.593508  [  500/ 3589]\n",
      "loss: 1.637489  [ 1000/ 3589]\n",
      "loss: 1.781230  [ 1500/ 3589]\n",
      "loss: 1.198561  [ 2000/ 3589]\n",
      "loss: 1.847631  [ 2500/ 3589]\n",
      "loss: 1.595307  [ 3000/ 3589]\n",
      "loss: 1.964805  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.6083 \tAverage TrainAcc: 0.3658\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5490 \tAverage ValAcc: 0.3973\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.818354  [    0/ 3589]\n",
      "loss: 1.624675  [  500/ 3589]\n",
      "loss: 1.012524  [ 1000/ 3589]\n",
      "loss: 1.342550  [ 1500/ 3589]\n",
      "loss: 1.623425  [ 2000/ 3589]\n",
      "loss: 1.521486  [ 2500/ 3589]\n",
      "loss: 1.535798  [ 3000/ 3589]\n",
      "loss: 1.473163  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.5983 \tAverage TrainAcc: 0.3717\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5418 \tAverage ValAcc: 0.4037\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.533559  [    0/ 3589]\n",
      "loss: 1.937035  [  500/ 3589]\n",
      "loss: 1.501003  [ 1000/ 3589]\n",
      "loss: 1.737491  [ 1500/ 3589]\n",
      "loss: 1.458627  [ 2000/ 3589]\n",
      "loss: 1.014896  [ 2500/ 3589]\n",
      "loss: 2.237238  [ 3000/ 3589]\n",
      "loss: 1.888800  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.5942 \tAverage TrainAcc: 0.3728\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5274 \tAverage ValAcc: 0.4051\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.324269  [    0/ 3589]\n",
      "loss: 1.289897  [  500/ 3589]\n",
      "loss: 1.378744  [ 1000/ 3589]\n",
      "loss: 2.318770  [ 1500/ 3589]\n",
      "loss: 1.640895  [ 2000/ 3589]\n",
      "loss: 2.038977  [ 2500/ 3589]\n",
      "loss: 1.586905  [ 3000/ 3589]\n",
      "loss: 1.585498  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.5874 \tAverage TrainAcc: 0.3792\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5233 \tAverage ValAcc: 0.4085\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.977946  [    0/ 3589]\n",
      "loss: 1.401165  [  500/ 3589]\n",
      "loss: 1.406076  [ 1000/ 3589]\n",
      "loss: 1.670222  [ 1500/ 3589]\n",
      "loss: 1.127987  [ 2000/ 3589]\n",
      "loss: 1.620671  [ 2500/ 3589]\n",
      "loss: 1.365102  [ 3000/ 3589]\n",
      "loss: 1.404389  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.5858 \tAverage TrainAcc: 0.3763\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5289 \tAverage ValAcc: 0.4082\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.484684  [    0/ 3589]\n",
      "loss: 1.687183  [  500/ 3589]\n",
      "loss: 1.198510  [ 1000/ 3589]\n",
      "loss: 1.553473  [ 1500/ 3589]\n",
      "loss: 1.536642  [ 2000/ 3589]\n",
      "loss: 1.651952  [ 2500/ 3589]\n",
      "loss: 1.880142  [ 3000/ 3589]\n",
      "loss: 1.704975  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.5827 \tAverage TrainAcc: 0.3765\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5185 \tAverage ValAcc: 0.4118\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.586080  [    0/ 3589]\n",
      "loss: 1.877907  [  500/ 3589]\n",
      "loss: 1.671934  [ 1000/ 3589]\n",
      "loss: 1.415186  [ 1500/ 3589]\n",
      "loss: 1.509403  [ 2000/ 3589]\n",
      "loss: 1.527495  [ 2500/ 3589]\n",
      "loss: 1.563862  [ 3000/ 3589]\n",
      "loss: 1.130296  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.5834 \tAverage TrainAcc: 0.3751\n",
      "Evaluation:\n",
      "Average ValLoss: 1.5198 \tAverage ValAcc: 0.4099\n",
      "\n",
      "\n",
      "Training complete in 15m 9s\n"
     ]
    }
   ],
   "source": [
    "# Start training and val loops\n",
    "\n",
    "since = time.time()\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, 500)\n",
    "    print(f'Average TrainLoss: {train_loss:.4f} \\tAverage TrainAcc: {train_acc:.4f}')\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"Evaluation:\")\n",
    "    val_loss, val_acc = val_epoch(model, val_loader, criterion, device)\n",
    "    print(f'Average ValLoss: {val_loss:.4f} \\tAverage ValAcc: {val_acc:.4f}')\n",
    "    \n",
    "    # log metrics \n",
    "    if writer:\n",
    "        writer.add_scalar(\"train_loss\", train_loss, epoch)\n",
    "        writer.add_scalar(\"train_accuracy\", train_acc, epoch)\n",
    "        writer.add_scalar(\"val_loss\", val_loss, epoch)\n",
    "        writer.add_scalar(\"val_accuracy\", val_acc, epoch)\n",
    "    \n",
    "    # schedule lr\n",
    "    scheduler.step(val_loss)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "print(f\"Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa15c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), cfg.MODEL_DIR + \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2785c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aff473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
