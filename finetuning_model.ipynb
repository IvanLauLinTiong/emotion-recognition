{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eabf088",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a164957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15f8b7",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c553bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"angry\", \n",
    "    \"disgust\", \n",
    "    \"fear\", \n",
    "    \"happy\", \n",
    "    \"sad\", \n",
    "    \"surprise\", \n",
    "    \"neutral\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ac1f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # dataset\n",
    "    TRAIN_DS_PATH = './dataset/train.csv'\n",
    "    VAL_DS_PATH = './dataset/val.csv'\n",
    "    TEST_DS_PATH = './dataset/finaltest.csv'\n",
    "    \n",
    "    # images dir\n",
    "    TRAIN_IMG_DIR = './dataset/train/'\n",
    "    VAL_IMG_DIR  = './dataset/val/'\n",
    "    TEST_IMG_DIR  = './dataset/finaltest/'\n",
    "    \n",
    "    # training hyperparams\n",
    "    EPOCHS = 1\n",
    "    LR = 1e-4\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 0\n",
    "    SHUFFLE = True\n",
    "    \n",
    "    # saved model path\n",
    "    MODEL_DIR = './model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a43450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e237c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard writer\n",
    "writer = SummaryWriter(\"runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd927d2d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e5d1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://github.com/omarsayed7/Deep-Emotion/blob/master/data_loaders.py\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, datatype, transform):\n",
    "        '''\n",
    "        Pytorch Dataset class\n",
    "        params:-\n",
    "                 csv_file : the path of the csv file    (train, validation, test)\n",
    "                 img_dir  : the directory of the images (train, validation, test)\n",
    "                 datatype : data type for the dataset   (train, val, test)\n",
    "                 transform: pytorch transformation over the data\n",
    "        return :-\n",
    "                 image, labels\n",
    "        '''\n",
    "        self.csv_file = pd.read_csv(csv_file)\n",
    "        self.labels = self.csv_file['emotion']\n",
    "        self.img_dir = img_dir\n",
    "        self.datatype = datatype\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img = Image.open(self.img_dir + self.datatype + str(idx) + '.jpg').convert('RGB')\n",
    "        labels = np.array(self.labels[idx])\n",
    "        labels = torch.from_numpy(labels).long()\n",
    "\n",
    "        if self.transform :\n",
    "            img = self.transform(img)\n",
    "        return img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f93828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranformations\n",
    "transformation= transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "#     transforms.Grayscale(3), # no need this since you .convert(\"RGB\") at __getitem__\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b08a71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "train_dataset = EmotionDataset(\n",
    "    csv_file=cfg.TRAIN_DS_PATH, \n",
    "    img_dir=cfg.TRAIN_IMG_DIR,\n",
    "    datatype='train',\n",
    "    transform=transformation\n",
    ")\n",
    "\n",
    "validation_dataset = EmotionDataset(\n",
    "    csv_file=cfg.VAL_DS_PATH, \n",
    "    img_dir=cfg.VAL_IMG_DIR,\n",
    "    datatype='val',\n",
    "    transform = transformation\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = EmotionDataset(\n",
    "    csv_file=cfg.TEST_DS_PATH, \n",
    "    img_dir=cfg.TEST_IMG_DIR,\n",
    "    datatype='finaltest',\n",
    "    transform = transformation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dc12830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=cfg.BATCH_SIZE, \n",
    "    shuffle =cfg.SHUFFLE, \n",
    "    num_workers=cfg.NUM_WORKERS\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    validation_dataset, \n",
    "    batch_size=cfg.BATCH_SIZE, \n",
    "    shuffle =cfg.SHUFFLE, \n",
    "    num_workers=cfg.NUM_WORKERS\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=cfg.BATCH_SIZE, \n",
    "    shuffle =cfg.SHUFFLE, \n",
    "    num_workers=cfg.NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2bf307",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df7f4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, steps_print_loss=0):\n",
    "    \"\"\"Train the model for 1 epoch\n",
    "    Args:\n",
    "        model: nn.Module\n",
    "        train_loader: train DataLoader\n",
    "        criterion: callable loss function\n",
    "        optimizer: pytorch optimizer\n",
    "        device: torch.device\n",
    "        steps_print_loss: loss will print out in every specified steps.\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Float, Float]\n",
    "        average train loss and average train accuracy for current epoch\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    train_corrects = []\n",
    "    model.train()\n",
    "\n",
    "    # Iterate over data.\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # prediction\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # statistics\n",
    "        train_losses.append(loss.item())\n",
    "        train_corrects.append(torch.sum(preds == labels.data).item())\n",
    "        \n",
    "        if steps_print_loss and (batch_idx % steps_print_loss == 0):\n",
    "            print(f\"loss: {loss.item():>7f}  [{batch_idx:>5d}/{len(train_loader):>5d}]\")\n",
    "        \n",
    "    train_loss = sum(train_losses)/len(train_losses)\n",
    "    train_accuracy = sum(train_corrects)/len(train_loader.dataset)      \n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "def val_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model for 1 epoch\n",
    "    Args:\n",
    "        model: nn.Module\n",
    "        val_loader: val DataLoader\n",
    "        criterion: callable loss function\n",
    "        device: torch.device\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[Float, Float]\n",
    "        average val loss and average val accuracy for current epoch\n",
    "    \"\"\"\n",
    "\n",
    "    val_losses = []\n",
    "    val_corrects = []\n",
    "    model.eval()\n",
    "\n",
    "    # Iterate over data\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # prediction\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # calculate loss\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # statistics\n",
    "            val_losses.append(loss.item())\n",
    "            val_corrects.append(torch.sum(preds == labels.data).item())\n",
    "            \n",
    "        val_loss = sum(val_losses)/len(val_losses)\n",
    "        val_accuracy = sum(val_corrects)/len(val_loader.dataset)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309145e",
   "metadata": {},
   "source": [
    "# Training and Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19b36628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = models.mobilenet.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "888b5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efe3cfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "# transfer to cuda device if any\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c76f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, optimizer and scheduler \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=cfg.LR)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3a93309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.027109  [    0/ 3589]\n",
      "loss: 1.869347  [  500/ 3589]\n",
      "loss: 1.941542  [ 1000/ 3589]\n",
      "loss: 1.608768  [ 1500/ 3589]\n",
      "loss: 1.568424  [ 2000/ 3589]\n",
      "loss: 1.958847  [ 2500/ 3589]\n",
      "loss: 1.572384  [ 3000/ 3589]\n",
      "loss: 1.723830  [ 3500/ 3589]\n",
      "Average TrainLoss: 1.7177 \tAverage TrainAcc: 0.3018\n",
      "Evaluation:\n",
      "Average ValLoss: 1.6362 \tAverage ValAcc: 0.3703\n",
      "\n",
      "\n",
      "Training complete in 2m 38s\n"
     ]
    }
   ],
   "source": [
    "# Start training and val loops\n",
    "\n",
    "since = time.time()\n",
    "for epoch in range(cfg.EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, 500)\n",
    "    print(f'Average TrainLoss: {train_loss:.4f} \\tAverage TrainAcc: {train_acc:.4f}')\n",
    "    \n",
    "    # Evaluation\n",
    "    print(\"Evaluation:\")\n",
    "    val_loss, val_acc = val_epoch(model, val_loader, criterion, device)\n",
    "    print(f'Average ValLoss: {val_loss:.4f} \\tAverage ValAcc: {val_acc:.4f}')\n",
    "    \n",
    "    # log metrics \n",
    "    if writer:\n",
    "        writer.add_scalar(\"train_loss\", train_loss, epoch)\n",
    "        writer.add_scalar(\"train_accuracy\", train_acc, epoch)\n",
    "        writer.add_scalar(\"val_loss\", val_loss, epoch)\n",
    "        writer.add_scalar(\"val_accuracy\", val_acc, epoch)\n",
    "    \n",
    "    # schedule lr\n",
    "    scheduler.step(val_loss)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "print(f\"Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0eee5",
   "metadata": {},
   "source": [
    "# Evaluating on Unseen Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad3ffe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TestLoss: 1.6329 \tAverage TestAcc: 0.3525\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "test_corrects = []\n",
    "\n",
    "model.eval()\n",
    "# Iterate over data\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # prediction\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # calculate loss\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # statistics\n",
    "        test_losses.append(loss.item())\n",
    "        test_corrects.append(torch.sum(preds == labels.data).item())\n",
    "\n",
    "    test_loss = sum(test_losses)/len(test_losses)\n",
    "    test_accuracy = sum(test_corrects)/len(test_loader.dataset)\n",
    "    \n",
    "print(f'Average TestLoss: {test_loss:.4f} \\tAverage TestAcc: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee000e",
   "metadata": {},
   "source": [
    "# Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_name = f\"model_epoch{cfg.EPOCHS}_lr{cfg.LR}_batch{cfg.BATCH_SIZE}.pt\"\n",
    "torch.save(model.state_dict(), cfg.MODEL_DIR + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2785c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aff473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
