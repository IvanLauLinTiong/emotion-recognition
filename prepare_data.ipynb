{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e69294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca49f876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: ok\n"
     ]
    }
   ],
   "source": [
    "# Uncomment this line to enable nbextension and restart the kernel before proceeding to next step\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab96ed7e",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95924cd5",
   "metadata": {},
   "source": [
    "Download data from Kaggle [here](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data) and unzip it to retrieve `fer2013.csv`  file and place the file to a folder named as `dataset`. The file path would be `./dataset/fer2013.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab987ab3",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52bb0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate_data():\n",
    "    \"\"\"\n",
    "    Reference: https://github.com/omarsayed7/Deep-Emotion/blob/master/generate_data.py\n",
    "    \"\"\"\n",
    "    def __init__(self, datapath):\n",
    "        \"\"\"\n",
    "        Generate_data class\n",
    "        Two methods to be used\n",
    "        1-split_test\n",
    "        2-save_images\n",
    "        [Note] that you have to split the public and private from fer2013 file\n",
    "        \"\"\"\n",
    "        self.data_path = datapath\n",
    "\n",
    "    def split_test(self, train_filename='train', test_filename='finaltest', val_filename='val'):\n",
    "        \"\"\"\n",
    "        Helper function to split the validation and test data from general test file as it contains (Public test, Private test)\n",
    "            params:-\n",
    "                data_path = path to the folder that contains the test data file\n",
    "        \"\"\"\n",
    "        csv_path = self.data_path +\"/\"+ 'fer2013.csv'\n",
    "        fer_df = pd.read_csv(csv_path)\n",
    "        \n",
    "        train_data = fer_df[fer_df['Usage'] == 'Training'].reset_index(drop=True)\n",
    "        validation_data = fer_df[fer_df['Usage'] == 'PublicTest'].reset_index(drop=True)\n",
    "        test_data = fer_df[fer_df['Usage'] == 'PrivateTest'].reset_index(drop=True)\n",
    "        \n",
    "        train_data.to_csv(self.data_path+\"/\"+train_filename+\".csv\")\n",
    "        test_data.to_csv(self.data_path+\"/\"+test_filename+\".csv\")\n",
    "        validation_data.to_csv(self.data_path+\"/\"+val_filename+\".csv\")\n",
    "        \n",
    "        print(\"Done splitting the test file into validation & final test file\")\n",
    "\n",
    "    def str_to_image(self, str_img = ' '):\n",
    "        '''\n",
    "        Convert string pixels from the csv file into image object\n",
    "            params:- take an image string\n",
    "            return :- return PIL image object\n",
    "        '''\n",
    "        imgarray_str = str_img.split(' ')\n",
    "        imgarray = np.asarray(imgarray_str,dtype=np.uint8).reshape(48,48)\n",
    "        return Image.fromarray(imgarray)\n",
    "\n",
    "    def save_images(self, datatype='train'):\n",
    "        '''\n",
    "        save_images is a function responsible for saving images from data files e.g(train, test) in a desired folder\n",
    "            params:-\n",
    "            datatype= str e.g (train, val, finaltest)\n",
    "        '''\n",
    "        foldername= self.data_path+\"/\"+datatype\n",
    "        csvfile_path= self.data_path+\"/\"+datatype+'.csv'\n",
    "        if not os.path.exists(foldername):\n",
    "            os.mkdir(foldername)\n",
    "\n",
    "        data = pd.read_csv(csvfile_path)\n",
    "        images = data['pixels'] #dataframe to series pandas\n",
    "        numberofimages = images.shape[0]\n",
    "        for index in tqdm(range(numberofimages)):\n",
    "            img = self.str_to_image(images[index])\n",
    "            img.save(os.path.join(foldername,'{}{}.jpg'.format(datatype,index)),'JPEG')\n",
    "        print('Done saving {} data'.format((foldername)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbebacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4772a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = Generate_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a25b6",
   "metadata": {},
   "source": [
    "# Split Images to Test and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d43457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done splitting the test file into validation & final test file\n"
     ]
    }
   ],
   "source": [
    "data_gen.split_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98d387",
   "metadata": {},
   "source": [
    "# Create Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db42430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87ca3ebd5ae483184bec5a2ee1a9c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving ./dataset//train data\n"
     ]
    }
   ],
   "source": [
    "data_gen.save_images('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d1acc",
   "metadata": {},
   "source": [
    "# Create Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b414d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2df464218c42128dd97e1a6a0768a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving ./dataset//finaltest data\n"
     ]
    }
   ],
   "source": [
    "data_gen.save_images('finaltest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa19772",
   "metadata": {},
   "source": [
    "# Create Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55e79cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff514f3041d41e5bac93ef7ffec542d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving ./dataset//val data\n"
     ]
    }
   ],
   "source": [
    "data_gen.save_images('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fac127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0161950f",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a31d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48 at 0x222203B75E0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4\n",
    "img = Image.open(f'./dataset/train/train{i}.jpg')\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1292dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = np.array(img)\n",
    "img_array.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
